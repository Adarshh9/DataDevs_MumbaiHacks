{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7203112,"sourceType":"datasetVersion","datasetId":4166933}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"level_data = [\n  {\n    \"text\": \"Aspiring AI enthusiast with a foundational understanding of machine learning and neural networks...\",\n    \"skills\": [\"Python\", \"Machine Learning\"],\n    \"projects\": [\n      {\"name\": \"Basic Image Classification\", \"description\": \"Implemented a basic image classification model using a simple neural network.\", \"github_link\": \"\"},\n      {\"name\": \"Predictive Model for Iris Dataset\", \"description\": \"Developed a predictive model for the Iris dataset using Scikit-learn.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"Scikit-learn\"],\n    \"frameworks\": [],\n    \"experience_level\": \"Beginner\"\n  },\n  \n\n  {\n    \"text\": \"AI intern with foundational skills in machine learning algorithms and data preprocessing techniques...\",\n    \"skills\": [\"Python\", \"Machine Learning\", \"Data Preprocessing\"],\n    \"projects\": [\n      {\"name\": \"Predictive Analytics for Sales\", \"description\": \"Applied machine learning for predictive analytics on sales data.\", \"github_link\": \"\"},\n      {\"name\": \"Data Cleaning and Transformation\", \"description\": \"Performed data cleaning and transformation tasks using Python.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"Pandas\", \"Scikit-learn\"],\n    \"frameworks\": [],\n    \"experience_level\": \"Beginner\"\n  },\n  \n\n  {\n    \"text\": \"AI researcher with intermediate skills in deep learning and computer vision applications...\",\n    \"skills\": [\"Python\", \"Deep Learning\", \"Computer Vision\"],\n    \"projects\": [\n      {\"name\": \"Object Detection with YOLO\", \"description\": \"Implemented object detection using YOLO (You Only Look Once).\", \"github_link\": \"\"},\n      {\"name\": \"Facial Recognition System\", \"description\": \"Developed a facial recognition system using deep learning techniques.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"TensorFlow\", \"OpenCV\"],\n    \"frameworks\": [\"Deep Learning\"],\n    \"experience_level\": \"Intermediate\"\n  },\n  \n\n  {\n    \"text\": \"AI engineer specializing in natural language processing (NLP) with intermediate proficiency...\",\n    \"skills\": [\"Python\", \"NLP\", \"Deep Learning\"],\n    \"projects\": [\n      {\"name\": \"Sentiment Analysis for Social Media\", \"description\": \"Conducted sentiment analysis on social media data using NLP.\", \"github_link\": \"\"},\n      {\"name\": \"Chatbot Development\", \"description\": \"Built a chatbot using deep learning for natural language understanding.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"NLTK\", \"Transformers\"],\n    \"frameworks\": [\"Deep Learning\", \"NLP\"],\n    \"experience_level\": \"Intermediate\"\n  },\n  \n\n  {\n    \"text\": \"Lead AI scientist with extensive research contributions in reinforcement learning and AI ethics...\",\n    \"skills\": [\"Python\", \"Reinforcement Learning\", \"AI Ethics\"],\n    \"projects\": [\n      {\"name\": \"Advanced Reinforcement Learning Models\", \"description\": \"Contributed to the development of advanced reinforcement learning models.\", \"github_link\": \"\"},\n      {\"name\": \"Ethical AI Framework\", \"description\": \"Led the creation of an ethical framework for AI applications.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"PyTorch\", \"OpenAI Gym\"],\n    \"frameworks\": [\"Reinforcement Learning\"],\n    \"experience_level\": \"Advanced\"\n  },\n  \n\n  {\n    \"text\": \"Senior AI engineer with extensive experience and publications in AI and machine learning...\",\n    \"skills\": [\"Python\", \"Machine Learning\", \"Research Publications\"],\n    \"projects\": [\n      {\"name\": \"Published Paper on GANs\", \"description\": \"Contributed to a research paper on Generative Adversarial Networks (GANs).\", \"github_link\": \"\"},\n      {\"name\": \"AI-driven Healthcare Solutions\", \"description\": \"Developed AI-driven solutions for healthcare applications.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"TensorFlow\", \"Scikit-learn\"],\n    \"frameworks\": [\"Machine Learning\"],\n    \"experience_level\": \"Advanced\"\n  },\n  \n\n  {\n    \"text\": \"Aspiring web developer with foundational skills in HTML, CSS, and JavaScript...\",\n    \"skills\": [\"HTML\", \"CSS\", \"JavaScript\"],\n    \"projects\": [\n      {\"name\": \"Portfolio Website\", \"description\": \"Created a personal portfolio website to showcase projects and skills.\", \"github_link\": \"\"},\n      {\"name\": \"Simple To-Do App\", \"description\": \"Developed a basic to-do application using HTML, CSS, and JavaScript.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [],\n    \"frameworks\": [],\n    \"experience_level\": \"Beginner\"\n  },\n  \n\n  {\n    \"text\": \"Junior frontend developer with beginner-to-intermediate skills in modern web technologies...\",\n    \"skills\": [\"HTML5\", \"CSS3\", \"JavaScript\", \"React\"],\n    \"projects\": [\n      {\"name\": \"Responsive Website with React\", \"description\": \"Developed a responsive website using React for enhanced user experience.\", \"github_link\": \"\"},\n      {\"name\": \"Interactive Frontend Features\", \"description\": \"Implemented interactive features on the frontend using JavaScript.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"React\", \"Visual Studio Code\"],\n    \"frameworks\": [],\n    \"experience_level\": \"Beginner\"\n  },\n  \n\n  {\n    \"text\": \"Experienced full stack developer with intermediate proficiency in both frontend and backend technologies...\",\n    \"skills\": [\"HTML5\", \"CSS3\", \"JavaScript\", \"Node.js\", \"Express.js\", \"MongoDB\"],\n    \"projects\": [\n      {\"name\": \"Full Stack E-commerce Platform\", \"description\": \"Architected and developed a full-stack e-commerce platform.\", \"github_link\": \"\"},\n      {\"name\": \"Real-time Chat Application\", \"description\": \"Built a real-time chat application using Node.js and Socket.io.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"Git\", \"Postman\"],\n    \"frameworks\": [\"Node.js\", \"Express.js\"],\n    \"experience_level\": \"Intermediate\"\n  },\n  \n\n  {\n    \"text\": \"Intermediate UI/UX designer with proficiency in creating visually appealing and user-friendly interfaces...\",\n    \"skills\": [\"UI/UX Design\", \"Adobe XD\", \"Figma\"],\n    \"projects\": [\n      {\"name\": \"Redesign of E-commerce Website\", \"description\": \"Led the redesign of an e-commerce website for improved user experience.\", \"github_link\": \"\"},\n      {\"name\": \"Mobile App Interface Design\", \"description\": \"Designed the interface for a mobile application with a focus on usability.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"Adobe XD\", \"Figma\"],\n    \"frameworks\": [],\n    \"experience_level\": \"Intermediate\"\n  },\n  \n\n  {\n    \"text\": \"Lead backend developer with advanced skills in designing scalable and efficient server architectures...\",\n    \"skills\": [\"Node.js\", \"Express.js\", \"Databases\", \"RESTful APIs\"],\n    \"projects\": [\n      {\"name\": \"Scalable Microservices Architecture\", \"description\": \"Designed a scalable microservices architecture for a complex system.\", \"github_link\": \"\"},\n      {\"name\": \"Optimization of Database Queries\", \"description\": \"Optimized database queries for improved application performance.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"Docker\", \"PostgreSQL\"],\n    \"frameworks\": [\"Node.js\", \"Express.js\"],\n    \"experience_level\": \"Advanced\"\n  },\n  \n\n  {\n    \"text\": \"Senior frontend developer with advanced proficiency in modern frontend frameworks and library contributions...\",\n    \"skills\": [\"React\", \"Vue.js\", \"JavaScript\", \"CSS-in-JS\"],\n    \"projects\": [\n      {\"name\": \"Contributions to React Library\", \"description\": \"Contributed to the development of a popular React library.\", \"github_link\": \"\"},\n      {\"name\": \"Scalable Frontend Architecture\", \"description\": \"Led the development of a scalable architecture for a large-scale frontend application.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"Webpack\", \"Redux\"],\n    \"frameworks\": [\"React\", \"Vue.js\"],\n    \"experience_level\": \"Advanced\"\n  },\n    \n  {\n  \"text\": \"Senior researcher with a focus on cutting-edge machine learning algorithms and applications...\",\n  \"skills\": [\"Python\", \"Deep Learning\", \"NLP\"],\n  \"projects\": [\n    {\"name\": \"Advanced NLP Models\", \"description\": \"Developed advanced natural language processing models for research purposes.\", \"github_link\": \"\"},\n    {\"name\": \"Deep Learning for Image Recognition\", \"description\": \"Led a team in applying deep learning techniques for image recognition.\", \"github_link\": \"\"}\n  ],\n  \"tools\": [\"TensorFlow\", \"PyTorch\"],\n  \"frameworks\": [\"Deep Learning\", \"NLP\"],\n  \"experience_level\": \"Advanced\"\n},\n\n{\n  \"text\": \"Experienced full stack developer leading teams in building scalable and robust web applications...\",\n  \"skills\": [\"Node.js\", \"React\", \"MongoDB\", \"Express.js\"],\n  \"projects\": [\n    {\"name\": \"Scalable API Development\", \"description\": \"Led the development of a scalable API using Node.js and Express.js.\", \"github_link\": \"\"},\n    {\"name\": \"Full Stack E-commerce Platform\", \"description\": \"Architected and developed a full-stack e-commerce platform.\", \"github_link\": \"\"}\n  ],\n  \"tools\": [\"Postman\"],\n  \"frameworks\": [\"Node.js\", \"React\", \"Express.js\"],\n  \"experience_level\": \"Advanced\"\n},\n\n{\n  \"text\": \"Data science enthusiast with hands-on experience in statistical analysis and machine learning...\",\n  \"skills\": [\"Python\", \"Statistics\", \"Machine Learning\"],\n  \"projects\": [\n    {\"name\": \"Statistical Analysis of Sales Data\", \"description\": \"Conducted statistical analysis on sales data to extract insights.\", \"github_link\": \"\"},\n    {\"name\": \"Predictive Modeling\", \"description\": \"Developed predictive models for a given dataset using machine learning algorithms.\", \"github_link\": \"\"}\n  ],\n  \"tools\": [\"Scikit-learn\", \"Jupyter Notebooks\"],\n  \"frameworks\": [],\n  \"experience_level\": \"Intermediate\"\n},\n{\n  \"text\": \"Experienced frontend developer proficient in modern web technologies...\",\n  \"skills\": [\"HTML5\", \"CSS3\", \"JavaScript\", \"React\"],\n  \"projects\": [\n    {\"name\": \"E-commerce Website\", \"description\": \"Developed a responsive e-commerce website using React and Redux.\", \"github_link\": \"\"},\n    {\"name\": \"Interactive Web App\", \"description\": \"Built an interactive web application with advanced UI features.\", \"github_link\": \"\"}\n  ],\n  \"tools\": [],\n  \"frameworks\": [\"React\"],\n  \"experience_level\": \"Intermediate\"\n},\n{\n  \"text\": \"Entry-level data analyst with foundational skills in Python and data manipulation...\",\n  \"skills\": [\"Python\", \"Data Analysis\"],\n  \"projects\": [\n    {\"name\": \"Data Cleaning with Pandas\", \"description\": \"Performed data cleaning tasks using Pandas library in Python.\", \"github_link\": \"\"},\n    {\"name\": \"Exploratory Data Analysis\", \"description\": \"Conducted exploratory data analysis on a given dataset.\", \"github_link\": \"\"}\n  ],\n  \"tools\": [\"Pandas\", \"Matplotlib\"],\n  \"frameworks\": [],\n  \"experience_level\": \"Beginner\"\n},\n{\n  \"text\": \"Aspiring web developer with foundational skills in HTML, CSS, and JavaScript...\",\n  \"skills\": [\"HTML\", \"CSS\", \"JavaScript\"],\n  \"projects\": [\n    {\"name\": \"Portfolio Website\", \"description\": \"Created a personal portfolio website to showcase projects and skills.\", \"github_link\": \"\"},\n    {\"name\": \"Simple To-Do App\", \"description\": \"Developed a basic to-do application using HTML, CSS, and JavaScript.\", \"github_link\": \"\"}\n  ],\n  \"tools\": [],\n  \"frameworks\": [],\n  \"experience_level\": \"Beginner\"\n},\n{\n    \"text\": \"Experienced data scientist specializing in natural language processing and deep learning...\",\n    \"skills\": [\"Python\", \"NLP\", \"Deep Learning\"],\n    \"projects\": [\n      {\"name\": \"Sentiment Analysis with BERT\", \"description\": \"Implemented sentiment analysis using BERT pre-trained model.\"},\n      {\"name\": \"Text Generation with LSTM\", \"description\": \"Developed a text generation model using LSTM and trained on a large corpus.\"}\n    ],\n    \"tools\": [\"Transformers\", \"Tensorflow\", \"Keras\"],\n    \"frameworks\": [\"Deep Learning\", \"Natural Language Processing\"],\n    \"experience_level\": \"Advanced\"\n  },\n  {\n    \"text\": \"AI enthusiast with hands-on experience in computer vision and reinforcement learning...\",\n    \"skills\": [\"Python\", \"Computer Vision\", \"Reinforcement Learning\"],\n    \"projects\": [\n      {\"name\": \"Object Detection using OpenCV\", \"description\": \"Implemented an object detection system using OpenCV and Python.\"},\n      {\"name\": \"Reinforcement Learning Game\", \"description\": \"Developed a simple game with reinforcement learning algorithms for training agents.\"}\n    ],\n    \"tools\": [\"OpenCV\", \"Tensorflow\"],\n    \"frameworks\": [\"Deep Learning\", \"Reinforcement Learning\"],\n    \"experience_level\": \"Intermediate\"\n  },\n  {\n    \"text\": \"Recent graduate with a strong foundation in machine learning and data analysis...\",\n    \"skills\": [\"Python\", \"Data Analysis\"],\n    \"projects\": [\n      {\"name\": \"Data Analysis with Pandas\", \"description\": \"Explored and analyzed datasets using Pandas for data manipulation.\"},\n      {\"name\": \"Simple Machine Learning Model\", \"description\": \"Implemented a basic machine learning model using Scikit-learn for hands-on experience.\"}\n    ],\n    \"tools\": [\"Pandas\", \"Scikit-learn\"],\n    \"frameworks\": [\"Machine Learning\"],\n    \"experience_level\": \"Beginner\"\n  }\n]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-15T15:00:14.597646Z","iopub.execute_input":"2023-12-15T15:00:14.597984Z","iopub.status.idle":"2023-12-15T15:00:14.638939Z","shell.execute_reply.started":"2023-12-15T15:00:14.597951Z","shell.execute_reply":"2023-12-15T15:00:14.637926Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame(level_data)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:14.958295Z","iopub.execute_input":"2023-12-15T15:00:14.959099Z","iopub.status.idle":"2023-12-15T15:00:15.348121Z","shell.execute_reply.started":"2023-12-15T15:00:14.959066Z","shell.execute_reply":"2023-12-15T15:00:15.347163Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  Aspiring AI enthusiast with a foundational und...   \n1  AI intern with foundational skills in machine ...   \n2  AI researcher with intermediate skills in deep...   \n3  AI engineer specializing in natural language p...   \n4  Lead AI scientist with extensive research cont...   \n\n                                           skills  \\\n0                      [Python, Machine Learning]   \n1  [Python, Machine Learning, Data Preprocessing]   \n2        [Python, Deep Learning, Computer Vision]   \n3                    [Python, NLP, Deep Learning]   \n4     [Python, Reinforcement Learning, AI Ethics]   \n\n                                            projects                   tools  \\\n0  [{'name': 'Basic Image Classification', 'descr...          [Scikit-learn]   \n1  [{'name': 'Predictive Analytics for Sales', 'd...  [Pandas, Scikit-learn]   \n2  [{'name': 'Object Detection with YOLO', 'descr...    [TensorFlow, OpenCV]   \n3  [{'name': 'Sentiment Analysis for Social Media...    [NLTK, Transformers]   \n4  [{'name': 'Advanced Reinforcement Learning Mod...   [PyTorch, OpenAI Gym]   \n\n                 frameworks experience_level  \n0                        []         Beginner  \n1                        []         Beginner  \n2           [Deep Learning]     Intermediate  \n3      [Deep Learning, NLP]     Intermediate  \n4  [Reinforcement Learning]         Advanced  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skills</th>\n      <th>projects</th>\n      <th>tools</th>\n      <th>frameworks</th>\n      <th>experience_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aspiring AI enthusiast with a foundational und...</td>\n      <td>[Python, Machine Learning]</td>\n      <td>[{'name': 'Basic Image Classification', 'descr...</td>\n      <td>[Scikit-learn]</td>\n      <td>[]</td>\n      <td>Beginner</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AI intern with foundational skills in machine ...</td>\n      <td>[Python, Machine Learning, Data Preprocessing]</td>\n      <td>[{'name': 'Predictive Analytics for Sales', 'd...</td>\n      <td>[Pandas, Scikit-learn]</td>\n      <td>[]</td>\n      <td>Beginner</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AI researcher with intermediate skills in deep...</td>\n      <td>[Python, Deep Learning, Computer Vision]</td>\n      <td>[{'name': 'Object Detection with YOLO', 'descr...</td>\n      <td>[TensorFlow, OpenCV]</td>\n      <td>[Deep Learning]</td>\n      <td>Intermediate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AI engineer specializing in natural language p...</td>\n      <td>[Python, NLP, Deep Learning]</td>\n      <td>[{'name': 'Sentiment Analysis for Social Media...</td>\n      <td>[NLTK, Transformers]</td>\n      <td>[Deep Learning, NLP]</td>\n      <td>Intermediate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lead AI scientist with extensive research cont...</td>\n      <td>[Python, Reinforcement Learning, AI Ethics]</td>\n      <td>[{'name': 'Advanced Reinforcement Learning Mod...</td>\n      <td>[PyTorch, OpenAI Gym]</td>\n      <td>[Reinforcement Learning]</td>\n      <td>Advanced</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"projects\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.349751Z","iopub.execute_input":"2023-12-15T15:00:15.350126Z","iopub.status.idle":"2023-12-15T15:00:15.356256Z","shell.execute_reply.started":"2023-12-15T15:00:15.350101Z","shell.execute_reply":"2023-12-15T15:00:15.355398Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[{'name': 'Basic Image Classification',\n  'description': 'Implemented a basic image classification model using a simple neural network.',\n  'github_link': ''},\n {'name': 'Predictive Model for Iris Dataset',\n  'description': 'Developed a predictive model for the Iris dataset using Scikit-learn.',\n  'github_link': ''}]"},"metadata":{}}]},{"cell_type":"code","source":"len(df[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.357427Z","iopub.execute_input":"2023-12-15T15:00:15.357759Z","iopub.status.idle":"2023-12-15T15:00:15.368285Z","shell.execute_reply.started":"2023-12-15T15:00:15.357728Z","shell.execute_reply":"2023-12-15T15:00:15.367407Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"21"},"metadata":{}}]},{"cell_type":"code","source":"x = []\nfor project_list in df[\"projects\"]:\n    y = []\n    for project in project_list:\n        y.append(project[\"description\"])\n    x.append(y)\nx","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.370796Z","iopub.execute_input":"2023-12-15T15:00:15.371149Z","iopub.status.idle":"2023-12-15T15:00:15.382401Z","shell.execute_reply.started":"2023-12-15T15:00:15.371113Z","shell.execute_reply":"2023-12-15T15:00:15.381502Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[['Implemented a basic image classification model using a simple neural network.',\n  'Developed a predictive model for the Iris dataset using Scikit-learn.'],\n ['Applied machine learning for predictive analytics on sales data.',\n  'Performed data cleaning and transformation tasks using Python.'],\n ['Implemented object detection using YOLO (You Only Look Once).',\n  'Developed a facial recognition system using deep learning techniques.'],\n ['Conducted sentiment analysis on social media data using NLP.',\n  'Built a chatbot using deep learning for natural language understanding.'],\n ['Contributed to the development of advanced reinforcement learning models.',\n  'Led the creation of an ethical framework for AI applications.'],\n ['Contributed to a research paper on Generative Adversarial Networks (GANs).',\n  'Developed AI-driven solutions for healthcare applications.'],\n ['Created a personal portfolio website to showcase projects and skills.',\n  'Developed a basic to-do application using HTML, CSS, and JavaScript.'],\n ['Developed a responsive website using React for enhanced user experience.',\n  'Implemented interactive features on the frontend using JavaScript.'],\n ['Architected and developed a full-stack e-commerce platform.',\n  'Built a real-time chat application using Node.js and Socket.io.'],\n ['Led the redesign of an e-commerce website for improved user experience.',\n  'Designed the interface for a mobile application with a focus on usability.'],\n ['Designed a scalable microservices architecture for a complex system.',\n  'Optimized database queries for improved application performance.'],\n ['Contributed to the development of a popular React library.',\n  'Led the development of a scalable architecture for a large-scale frontend application.'],\n ['Developed advanced natural language processing models for research purposes.',\n  'Led a team in applying deep learning techniques for image recognition.'],\n ['Led the development of a scalable API using Node.js and Express.js.',\n  'Architected and developed a full-stack e-commerce platform.'],\n ['Conducted statistical analysis on sales data to extract insights.',\n  'Developed predictive models for a given dataset using machine learning algorithms.'],\n ['Developed a responsive e-commerce website using React and Redux.',\n  'Built an interactive web application with advanced UI features.'],\n ['Performed data cleaning tasks using Pandas library in Python.',\n  'Conducted exploratory data analysis on a given dataset.'],\n ['Created a personal portfolio website to showcase projects and skills.',\n  'Developed a basic to-do application using HTML, CSS, and JavaScript.'],\n ['Implemented sentiment analysis using BERT pre-trained model.',\n  'Developed a text generation model using LSTM and trained on a large corpus.'],\n ['Implemented an object detection system using OpenCV and Python.',\n  'Developed a simple game with reinforcement learning algorithms for training agents.'],\n ['Explored and analyzed datasets using Pandas for data manipulation.',\n  'Implemented a basic machine learning model using Scikit-learn for hands-on experience.']]"},"metadata":{}}]},{"cell_type":"code","source":"df[\"projects\"] = x","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.383398Z","iopub.execute_input":"2023-12-15T15:00:15.383692Z","iopub.status.idle":"2023-12-15T15:00:15.395196Z","shell.execute_reply.started":"2023-12-15T15:00:15.383668Z","shell.execute_reply":"2023-12-15T15:00:15.394217Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.396247Z","iopub.execute_input":"2023-12-15T15:00:15.396520Z","iopub.status.idle":"2023-12-15T15:00:15.420698Z","shell.execute_reply.started":"2023-12-15T15:00:15.396497Z","shell.execute_reply":"2023-12-15T15:00:15.419716Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  Aspiring AI enthusiast with a foundational und...   \n1  AI intern with foundational skills in machine ...   \n2  AI researcher with intermediate skills in deep...   \n3  AI engineer specializing in natural language p...   \n4  Lead AI scientist with extensive research cont...   \n\n                                           skills  \\\n0                      [Python, Machine Learning]   \n1  [Python, Machine Learning, Data Preprocessing]   \n2        [Python, Deep Learning, Computer Vision]   \n3                    [Python, NLP, Deep Learning]   \n4     [Python, Reinforcement Learning, AI Ethics]   \n\n                                            projects                   tools  \\\n0  [Implemented a basic image classification mode...          [Scikit-learn]   \n1  [Applied machine learning for predictive analy...  [Pandas, Scikit-learn]   \n2  [Implemented object detection using YOLO (You ...    [TensorFlow, OpenCV]   \n3  [Conducted sentiment analysis on social media ...    [NLTK, Transformers]   \n4  [Contributed to the development of advanced re...   [PyTorch, OpenAI Gym]   \n\n                 frameworks experience_level  \n0                        []         Beginner  \n1                        []         Beginner  \n2           [Deep Learning]     Intermediate  \n3      [Deep Learning, NLP]     Intermediate  \n4  [Reinforcement Learning]         Advanced  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skills</th>\n      <th>projects</th>\n      <th>tools</th>\n      <th>frameworks</th>\n      <th>experience_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aspiring AI enthusiast with a foundational und...</td>\n      <td>[Python, Machine Learning]</td>\n      <td>[Implemented a basic image classification mode...</td>\n      <td>[Scikit-learn]</td>\n      <td>[]</td>\n      <td>Beginner</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AI intern with foundational skills in machine ...</td>\n      <td>[Python, Machine Learning, Data Preprocessing]</td>\n      <td>[Applied machine learning for predictive analy...</td>\n      <td>[Pandas, Scikit-learn]</td>\n      <td>[]</td>\n      <td>Beginner</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AI researcher with intermediate skills in deep...</td>\n      <td>[Python, Deep Learning, Computer Vision]</td>\n      <td>[Implemented object detection using YOLO (You ...</td>\n      <td>[TensorFlow, OpenCV]</td>\n      <td>[Deep Learning]</td>\n      <td>Intermediate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AI engineer specializing in natural language p...</td>\n      <td>[Python, NLP, Deep Learning]</td>\n      <td>[Conducted sentiment analysis on social media ...</td>\n      <td>[NLTK, Transformers]</td>\n      <td>[Deep Learning, NLP]</td>\n      <td>Intermediate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lead AI scientist with extensive research cont...</td>\n      <td>[Python, Reinforcement Learning, AI Ethics]</td>\n      <td>[Contributed to the development of advanced re...</td>\n      <td>[PyTorch, OpenAI Gym]</td>\n      <td>[Reinforcement Learning]</td>\n      <td>Advanced</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"skills\"]=df[\"skills\"].apply(lambda x: [i.replace(\" \",\"\") for i in x] )\ndf[\"tools\"]=df[\"tools\"].apply(lambda x: [i.replace(\" \",\"\") for i in x] )\ndf[\"frameworks\"]=df[\"frameworks\"].apply(lambda x: [i.replace(\" \",\"\") for i in x] )\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.421726Z","iopub.execute_input":"2023-12-15T15:00:15.422016Z","iopub.status.idle":"2023-12-15T15:00:15.444986Z","shell.execute_reply.started":"2023-12-15T15:00:15.421992Z","shell.execute_reply":"2023-12-15T15:00:15.444036Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  Aspiring AI enthusiast with a foundational und...   \n1  AI intern with foundational skills in machine ...   \n2  AI researcher with intermediate skills in deep...   \n3  AI engineer specializing in natural language p...   \n4  Lead AI scientist with extensive research cont...   \n\n                                         skills  \\\n0                     [Python, MachineLearning]   \n1  [Python, MachineLearning, DataPreprocessing]   \n2        [Python, DeepLearning, ComputerVision]   \n3                   [Python, NLP, DeepLearning]   \n4     [Python, ReinforcementLearning, AIEthics]   \n\n                                            projects                   tools  \\\n0  [Implemented a basic image classification mode...          [Scikit-learn]   \n1  [Applied machine learning for predictive analy...  [Pandas, Scikit-learn]   \n2  [Implemented object detection using YOLO (You ...    [TensorFlow, OpenCV]   \n3  [Conducted sentiment analysis on social media ...    [NLTK, Transformers]   \n4  [Contributed to the development of advanced re...    [PyTorch, OpenAIGym]   \n\n                frameworks experience_level  \n0                       []         Beginner  \n1                       []         Beginner  \n2           [DeepLearning]     Intermediate  \n3      [DeepLearning, NLP]     Intermediate  \n4  [ReinforcementLearning]         Advanced  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skills</th>\n      <th>projects</th>\n      <th>tools</th>\n      <th>frameworks</th>\n      <th>experience_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aspiring AI enthusiast with a foundational und...</td>\n      <td>[Python, MachineLearning]</td>\n      <td>[Implemented a basic image classification mode...</td>\n      <td>[Scikit-learn]</td>\n      <td>[]</td>\n      <td>Beginner</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AI intern with foundational skills in machine ...</td>\n      <td>[Python, MachineLearning, DataPreprocessing]</td>\n      <td>[Applied machine learning for predictive analy...</td>\n      <td>[Pandas, Scikit-learn]</td>\n      <td>[]</td>\n      <td>Beginner</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AI researcher with intermediate skills in deep...</td>\n      <td>[Python, DeepLearning, ComputerVision]</td>\n      <td>[Implemented object detection using YOLO (You ...</td>\n      <td>[TensorFlow, OpenCV]</td>\n      <td>[DeepLearning]</td>\n      <td>Intermediate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AI engineer specializing in natural language p...</td>\n      <td>[Python, NLP, DeepLearning]</td>\n      <td>[Conducted sentiment analysis on social media ...</td>\n      <td>[NLTK, Transformers]</td>\n      <td>[DeepLearning, NLP]</td>\n      <td>Intermediate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lead AI scientist with extensive research cont...</td>\n      <td>[Python, ReinforcementLearning, AIEthics]</td>\n      <td>[Contributed to the development of advanced re...</td>\n      <td>[PyTorch, OpenAIGym]</td>\n      <td>[ReinforcementLearning]</td>\n      <td>Advanced</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"experience_level\"] = [[i] for i in df[\"experience_level\"]]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.446186Z","iopub.execute_input":"2023-12-15T15:00:15.446496Z","iopub.status.idle":"2023-12-15T15:00:15.454394Z","shell.execute_reply.started":"2023-12-15T15:00:15.446462Z","shell.execute_reply":"2023-12-15T15:00:15.453518Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df[\"text\"] = df[\"skills\"] + df[\"projects\"] + df[\"tools\"] + df[\"frameworks\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.455458Z","iopub.execute_input":"2023-12-15T15:00:15.455770Z","iopub.status.idle":"2023-12-15T15:00:15.465378Z","shell.execute_reply.started":"2023-12-15T15:00:15.455745Z","shell.execute_reply":"2023-12-15T15:00:15.464608Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.468175Z","iopub.execute_input":"2023-12-15T15:00:15.468462Z","iopub.status.idle":"2023-12-15T15:00:15.492148Z","shell.execute_reply.started":"2023-12-15T15:00:15.468437Z","shell.execute_reply":"2023-12-15T15:00:15.491216Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  [Python, MachineLearning, Implemented a basic ...   \n1  [Python, MachineLearning, DataPreprocessing, A...   \n2  [Python, DeepLearning, ComputerVision, Impleme...   \n3  [Python, NLP, DeepLearning, Conducted sentimen...   \n4  [Python, ReinforcementLearning, AIEthics, Cont...   \n\n                                         skills  \\\n0                     [Python, MachineLearning]   \n1  [Python, MachineLearning, DataPreprocessing]   \n2        [Python, DeepLearning, ComputerVision]   \n3                   [Python, NLP, DeepLearning]   \n4     [Python, ReinforcementLearning, AIEthics]   \n\n                                            projects                   tools  \\\n0  [Implemented a basic image classification mode...          [Scikit-learn]   \n1  [Applied machine learning for predictive analy...  [Pandas, Scikit-learn]   \n2  [Implemented object detection using YOLO (You ...    [TensorFlow, OpenCV]   \n3  [Conducted sentiment analysis on social media ...    [NLTK, Transformers]   \n4  [Contributed to the development of advanced re...    [PyTorch, OpenAIGym]   \n\n                frameworks experience_level  \n0                       []       [Beginner]  \n1                       []       [Beginner]  \n2           [DeepLearning]   [Intermediate]  \n3      [DeepLearning, NLP]   [Intermediate]  \n4  [ReinforcementLearning]       [Advanced]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skills</th>\n      <th>projects</th>\n      <th>tools</th>\n      <th>frameworks</th>\n      <th>experience_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Python, MachineLearning, Implemented a basic ...</td>\n      <td>[Python, MachineLearning]</td>\n      <td>[Implemented a basic image classification mode...</td>\n      <td>[Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[Python, MachineLearning, DataPreprocessing, A...</td>\n      <td>[Python, MachineLearning, DataPreprocessing]</td>\n      <td>[Applied machine learning for predictive analy...</td>\n      <td>[Pandas, Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[Python, DeepLearning, ComputerVision, Impleme...</td>\n      <td>[Python, DeepLearning, ComputerVision]</td>\n      <td>[Implemented object detection using YOLO (You ...</td>\n      <td>[TensorFlow, OpenCV]</td>\n      <td>[DeepLearning]</td>\n      <td>[Intermediate]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[Python, NLP, DeepLearning, Conducted sentimen...</td>\n      <td>[Python, NLP, DeepLearning]</td>\n      <td>[Conducted sentiment analysis on social media ...</td>\n      <td>[NLTK, Transformers]</td>\n      <td>[DeepLearning, NLP]</td>\n      <td>[Intermediate]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Python, ReinforcementLearning, AIEthics, Cont...</td>\n      <td>[Python, ReinforcementLearning, AIEthics]</td>\n      <td>[Contributed to the development of advanced re...</td>\n      <td>[PyTorch, OpenAIGym]</td>\n      <td>[ReinforcementLearning]</td>\n      <td>[Advanced]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.493279Z","iopub.execute_input":"2023-12-15T15:00:15.493630Z","iopub.status.idle":"2023-12-15T15:00:15.502844Z","shell.execute_reply.started":"2023-12-15T15:00:15.493569Z","shell.execute_reply":"2023-12-15T15:00:15.501966Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['Python',\n 'MachineLearning',\n 'Implemented a basic image classification model using a simple neural network.',\n 'Developed a predictive model for the Iris dataset using Scikit-learn.',\n 'Scikit-learn']"},"metadata":{}}]},{"cell_type":"code","source":"def remove_periods_in_list(lst):\n    return [item.replace('.', '') if isinstance(item, str) else item for item in lst]\ndf['text'] = df['text'].apply(lambda x: remove_periods_in_list(x))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.503932Z","iopub.execute_input":"2023-12-15T15:00:15.504186Z","iopub.status.idle":"2023-12-15T15:00:15.514420Z","shell.execute_reply.started":"2023-12-15T15:00:15.504163Z","shell.execute_reply":"2023-12-15T15:00:15.513527Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df[\"text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.515533Z","iopub.execute_input":"2023-12-15T15:00:15.517035Z","iopub.status.idle":"2023-12-15T15:00:15.527069Z","shell.execute_reply.started":"2023-12-15T15:00:15.517008Z","shell.execute_reply":"2023-12-15T15:00:15.526320Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['Python',\n 'MachineLearning',\n 'Implemented a basic image classification model using a simple neural network',\n 'Developed a predictive model for the Iris dataset using Scikit-learn',\n 'Scikit-learn']"},"metadata":{}}]},{"cell_type":"code","source":"df[\"text\"] = [[i.lower() for i in listt] for listt in df[\"text\"]]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.528098Z","iopub.execute_input":"2023-12-15T15:00:15.528379Z","iopub.status.idle":"2023-12-15T15:00:15.537364Z","shell.execute_reply.started":"2023-12-15T15:00:15.528346Z","shell.execute_reply":"2023-12-15T15:00:15.536610Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def remove_duplicates(skill_list):\n    return list(set(skill_list))\n\ndf['text'] = df['text'].apply(lambda x: remove_duplicates(x))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.538359Z","iopub.execute_input":"2023-12-15T15:00:15.538652Z","iopub.status.idle":"2023-12-15T15:00:15.548170Z","shell.execute_reply.started":"2023-12-15T15:00:15.538625Z","shell.execute_reply":"2023-12-15T15:00:15.547334Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df[\"text\"] = [\" \".join(i)for i in df[\"text\"]]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.550981Z","iopub.execute_input":"2023-12-15T15:00:15.551849Z","iopub.status.idle":"2023-12-15T15:00:15.558473Z","shell.execute_reply.started":"2023-12-15T15:00:15.551815Z","shell.execute_reply":"2023-12-15T15:00:15.557613Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.559628Z","iopub.execute_input":"2023-12-15T15:00:15.559886Z","iopub.status.idle":"2023-12-15T15:00:15.584961Z","shell.execute_reply.started":"2023-12-15T15:00:15.559863Z","shell.execute_reply":"2023-12-15T15:00:15.584070Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  machinelearning developed a predictive model f...   \n1  machinelearning performed data cleaning and tr...   \n2  developed a facial recognition system using de...   \n3  transformers deeplearning built a chatbot usin...   \n4  led the creation of an ethical framework for a...   \n\n                                         skills  \\\n0                     [Python, MachineLearning]   \n1  [Python, MachineLearning, DataPreprocessing]   \n2        [Python, DeepLearning, ComputerVision]   \n3                   [Python, NLP, DeepLearning]   \n4     [Python, ReinforcementLearning, AIEthics]   \n\n                                            projects                   tools  \\\n0  [Implemented a basic image classification mode...          [Scikit-learn]   \n1  [Applied machine learning for predictive analy...  [Pandas, Scikit-learn]   \n2  [Implemented object detection using YOLO (You ...    [TensorFlow, OpenCV]   \n3  [Conducted sentiment analysis on social media ...    [NLTK, Transformers]   \n4  [Contributed to the development of advanced re...    [PyTorch, OpenAIGym]   \n\n                frameworks experience_level  \n0                       []       [Beginner]  \n1                       []       [Beginner]  \n2           [DeepLearning]   [Intermediate]  \n3      [DeepLearning, NLP]   [Intermediate]  \n4  [ReinforcementLearning]       [Advanced]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skills</th>\n      <th>projects</th>\n      <th>tools</th>\n      <th>frameworks</th>\n      <th>experience_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>machinelearning developed a predictive model f...</td>\n      <td>[Python, MachineLearning]</td>\n      <td>[Implemented a basic image classification mode...</td>\n      <td>[Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>machinelearning performed data cleaning and tr...</td>\n      <td>[Python, MachineLearning, DataPreprocessing]</td>\n      <td>[Applied machine learning for predictive analy...</td>\n      <td>[Pandas, Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>developed a facial recognition system using de...</td>\n      <td>[Python, DeepLearning, ComputerVision]</td>\n      <td>[Implemented object detection using YOLO (You ...</td>\n      <td>[TensorFlow, OpenCV]</td>\n      <td>[DeepLearning]</td>\n      <td>[Intermediate]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>transformers deeplearning built a chatbot usin...</td>\n      <td>[Python, NLP, DeepLearning]</td>\n      <td>[Conducted sentiment analysis on social media ...</td>\n      <td>[NLTK, Transformers]</td>\n      <td>[DeepLearning, NLP]</td>\n      <td>[Intermediate]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>led the creation of an ethical framework for a...</td>\n      <td>[Python, ReinforcementLearning, AIEthics]</td>\n      <td>[Contributed to the development of advanced re...</td>\n      <td>[PyTorch, OpenAIGym]</td>\n      <td>[ReinforcementLearning]</td>\n      <td>[Advanced]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\n\ndef stem(obj):\n    y = []\n    for i in obj.split():\n        y.append(ps.stem(i))\n    \n    return \" \".join(y)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:15.586189Z","iopub.execute_input":"2023-12-15T15:00:15.586452Z","iopub.status.idle":"2023-12-15T15:00:16.707000Z","shell.execute_reply.started":"2023-12-15T15:00:15.586429Z","shell.execute_reply":"2023-12-15T15:00:16.706214Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df[\"text\"] = df[\"text\"].apply(stem)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:16.709482Z","iopub.execute_input":"2023-12-15T15:00:16.709800Z","iopub.status.idle":"2023-12-15T15:00:16.731408Z","shell.execute_reply.started":"2023-12-15T15:00:16.709774Z","shell.execute_reply":"2023-12-15T15:00:16.730437Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:16.732565Z","iopub.execute_input":"2023-12-15T15:00:16.732934Z","iopub.status.idle":"2023-12-15T15:00:16.752839Z","shell.execute_reply.started":"2023-12-15T15:00:16.732901Z","shell.execute_reply":"2023-12-15T15:00:16.751883Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  machinelearn develop a predict model for the i...   \n1  machinelearn perform data clean and transform ...   \n2  develop a facial recognit system use deep lear...   \n3  transform deeplearn built a chatbot use deep l...   \n4  led the creation of an ethic framework for ai ...   \n\n                                         skills  \\\n0                     [Python, MachineLearning]   \n1  [Python, MachineLearning, DataPreprocessing]   \n2        [Python, DeepLearning, ComputerVision]   \n3                   [Python, NLP, DeepLearning]   \n4     [Python, ReinforcementLearning, AIEthics]   \n\n                                            projects                   tools  \\\n0  [Implemented a basic image classification mode...          [Scikit-learn]   \n1  [Applied machine learning for predictive analy...  [Pandas, Scikit-learn]   \n2  [Implemented object detection using YOLO (You ...    [TensorFlow, OpenCV]   \n3  [Conducted sentiment analysis on social media ...    [NLTK, Transformers]   \n4  [Contributed to the development of advanced re...    [PyTorch, OpenAIGym]   \n\n                frameworks experience_level  \n0                       []       [Beginner]  \n1                       []       [Beginner]  \n2           [DeepLearning]   [Intermediate]  \n3      [DeepLearning, NLP]   [Intermediate]  \n4  [ReinforcementLearning]       [Advanced]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skills</th>\n      <th>projects</th>\n      <th>tools</th>\n      <th>frameworks</th>\n      <th>experience_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>machinelearn develop a predict model for the i...</td>\n      <td>[Python, MachineLearning]</td>\n      <td>[Implemented a basic image classification mode...</td>\n      <td>[Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>machinelearn perform data clean and transform ...</td>\n      <td>[Python, MachineLearning, DataPreprocessing]</td>\n      <td>[Applied machine learning for predictive analy...</td>\n      <td>[Pandas, Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>develop a facial recognit system use deep lear...</td>\n      <td>[Python, DeepLearning, ComputerVision]</td>\n      <td>[Implemented object detection using YOLO (You ...</td>\n      <td>[TensorFlow, OpenCV]</td>\n      <td>[DeepLearning]</td>\n      <td>[Intermediate]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>transform deeplearn built a chatbot use deep l...</td>\n      <td>[Python, NLP, DeepLearning]</td>\n      <td>[Conducted sentiment analysis on social media ...</td>\n      <td>[NLTK, Transformers]</td>\n      <td>[DeepLearning, NLP]</td>\n      <td>[Intermediate]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>led the creation of an ethic framework for ai ...</td>\n      <td>[Python, ReinforcementLearning, AIEthics]</td>\n      <td>[Contributed to the development of advanced re...</td>\n      <td>[PyTorch, OpenAIGym]</td>\n      <td>[ReinforcementLearning]</td>\n      <td>[Advanced]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:16.753899Z","iopub.execute_input":"2023-12-15T15:00:16.754140Z","iopub.status.idle":"2023-12-15T15:00:16.763776Z","shell.execute_reply.started":"2023-12-15T15:00:16.754119Z","shell.execute_reply":"2023-12-15T15:00:16.762854Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'machinelearn develop a predict model for the iri dataset use scikit-learn python scikit-learn implement a basic imag classif model use a simpl neural network'"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nnltk.download('stopwords')\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:16.764897Z","iopub.execute_input":"2023-12-15T15:00:16.765194Z","iopub.status.idle":"2023-12-15T15:00:16.936352Z","shell.execute_reply.started":"2023-12-15T15:00:16.765170Z","shell.execute_reply":"2023-12-15T15:00:16.935465Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"df['filtered_text'] = df['text'].apply(lambda sentence: ' '.join([word for word in word_tokenize(sentence) if word.lower() not in set(stopwords.words('english'))]))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:16.937634Z","iopub.execute_input":"2023-12-15T15:00:16.937996Z","iopub.status.idle":"2023-12-15T15:00:17.027647Z","shell.execute_reply.started":"2023-12-15T15:00:16.937964Z","shell.execute_reply":"2023-12-15T15:00:17.026731Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df[\"filtered_text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.028864Z","iopub.execute_input":"2023-12-15T15:00:17.029202Z","iopub.status.idle":"2023-12-15T15:00:17.035974Z","shell.execute_reply.started":"2023-12-15T15:00:17.029170Z","shell.execute_reply":"2023-12-15T15:00:17.035001Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'machinelearn develop predict model iri dataset use scikit-learn python scikit-learn implement basic imag classif model use simpl neural network'"},"metadata":{}}]},{"cell_type":"code","source":"df[\"filtered_text\"]=df[\"filtered_text\"].apply(lambda x: x.split())\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.037217Z","iopub.execute_input":"2023-12-15T15:00:17.037565Z","iopub.status.idle":"2023-12-15T15:00:17.065438Z","shell.execute_reply.started":"2023-12-15T15:00:17.037533Z","shell.execute_reply":"2023-12-15T15:00:17.064546Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  machinelearn develop a predict model for the i...   \n1  machinelearn perform data clean and transform ...   \n2  develop a facial recognit system use deep lear...   \n3  transform deeplearn built a chatbot use deep l...   \n4  led the creation of an ethic framework for ai ...   \n\n                                         skills  \\\n0                     [Python, MachineLearning]   \n1  [Python, MachineLearning, DataPreprocessing]   \n2        [Python, DeepLearning, ComputerVision]   \n3                   [Python, NLP, DeepLearning]   \n4     [Python, ReinforcementLearning, AIEthics]   \n\n                                            projects                   tools  \\\n0  [Implemented a basic image classification mode...          [Scikit-learn]   \n1  [Applied machine learning for predictive analy...  [Pandas, Scikit-learn]   \n2  [Implemented object detection using YOLO (You ...    [TensorFlow, OpenCV]   \n3  [Conducted sentiment analysis on social media ...    [NLTK, Transformers]   \n4  [Contributed to the development of advanced re...    [PyTorch, OpenAIGym]   \n\n                frameworks experience_level  \\\n0                       []       [Beginner]   \n1                       []       [Beginner]   \n2           [DeepLearning]   [Intermediate]   \n3      [DeepLearning, NLP]   [Intermediate]   \n4  [ReinforcementLearning]       [Advanced]   \n\n                                       filtered_text  \n0  [machinelearn, develop, predict, model, iri, d...  \n1  [machinelearn, perform, data, clean, transform...  \n2  [develop, facial, recognit, system, use, deep,...  \n3  [transform, deeplearn, built, chatbot, use, de...  \n4  [led, creation, ethic, framework, ai, applic, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>skills</th>\n      <th>projects</th>\n      <th>tools</th>\n      <th>frameworks</th>\n      <th>experience_level</th>\n      <th>filtered_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>machinelearn develop a predict model for the i...</td>\n      <td>[Python, MachineLearning]</td>\n      <td>[Implemented a basic image classification mode...</td>\n      <td>[Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n      <td>[machinelearn, develop, predict, model, iri, d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>machinelearn perform data clean and transform ...</td>\n      <td>[Python, MachineLearning, DataPreprocessing]</td>\n      <td>[Applied machine learning for predictive analy...</td>\n      <td>[Pandas, Scikit-learn]</td>\n      <td>[]</td>\n      <td>[Beginner]</td>\n      <td>[machinelearn, perform, data, clean, transform...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>develop a facial recognit system use deep lear...</td>\n      <td>[Python, DeepLearning, ComputerVision]</td>\n      <td>[Implemented object detection using YOLO (You ...</td>\n      <td>[TensorFlow, OpenCV]</td>\n      <td>[DeepLearning]</td>\n      <td>[Intermediate]</td>\n      <td>[develop, facial, recognit, system, use, deep,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>transform deeplearn built a chatbot use deep l...</td>\n      <td>[Python, NLP, DeepLearning]</td>\n      <td>[Conducted sentiment analysis on social media ...</td>\n      <td>[NLTK, Transformers]</td>\n      <td>[DeepLearning, NLP]</td>\n      <td>[Intermediate]</td>\n      <td>[transform, deeplearn, built, chatbot, use, de...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>led the creation of an ethic framework for ai ...</td>\n      <td>[Python, ReinforcementLearning, AIEthics]</td>\n      <td>[Contributed to the development of advanced re...</td>\n      <td>[PyTorch, OpenAIGym]</td>\n      <td>[ReinforcementLearning]</td>\n      <td>[Advanced]</td>\n      <td>[led, creation, ethic, framework, ai, applic, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"filtered_text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.071666Z","iopub.execute_input":"2023-12-15T15:00:17.072032Z","iopub.status.idle":"2023-12-15T15:00:17.078435Z","shell.execute_reply.started":"2023-12-15T15:00:17.072007Z","shell.execute_reply":"2023-12-15T15:00:17.077502Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['machinelearn',\n 'develop',\n 'predict',\n 'model',\n 'iri',\n 'dataset',\n 'use',\n 'scikit-learn',\n 'python',\n 'scikit-learn',\n 'implement',\n 'basic',\n 'imag',\n 'classif',\n 'model',\n 'use',\n 'simpl',\n 'neural',\n 'network']"},"metadata":{}}]},{"cell_type":"code","source":"df['filtered_text'] = df['filtered_text'].apply(lambda x: remove_duplicates(x))\ndf[\"filtered_text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.079793Z","iopub.execute_input":"2023-12-15T15:00:17.080161Z","iopub.status.idle":"2023-12-15T15:00:17.091923Z","shell.execute_reply.started":"2023-12-15T15:00:17.080127Z","shell.execute_reply":"2023-12-15T15:00:17.090866Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['machinelearn',\n 'dataset',\n 'predict',\n 'develop',\n 'model',\n 'classif',\n 'simpl',\n 'network',\n 'use',\n 'neural',\n 'python',\n 'scikit-learn',\n 'imag',\n 'iri',\n 'implement',\n 'basic']"},"metadata":{}}]},{"cell_type":"code","source":"df[\"final_text\"] = df['filtered_text'] + df[\"experience_level\"]\ndf[\"final_text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.093194Z","iopub.execute_input":"2023-12-15T15:00:17.093813Z","iopub.status.idle":"2023-12-15T15:00:17.105119Z","shell.execute_reply.started":"2023-12-15T15:00:17.093780Z","shell.execute_reply":"2023-12-15T15:00:17.104300Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"['machinelearn',\n 'dataset',\n 'predict',\n 'develop',\n 'model',\n 'classif',\n 'simpl',\n 'network',\n 'use',\n 'neural',\n 'python',\n 'scikit-learn',\n 'imag',\n 'iri',\n 'implement',\n 'basic',\n 'Beginner']"},"metadata":{}}]},{"cell_type":"code","source":"df[\"final_text\"] = df[\"final_text\"].apply(lambda x: \" \".join(x))\ndf[\"final_text\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.106216Z","iopub.execute_input":"2023-12-15T15:00:17.106482Z","iopub.status.idle":"2023-12-15T15:00:17.118377Z","shell.execute_reply.started":"2023-12-15T15:00:17.106453Z","shell.execute_reply":"2023-12-15T15:00:17.117545Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'machinelearn dataset predict develop model classif simpl network use neural python scikit-learn imag iri implement basic Beginner'"},"metadata":{}}]},{"cell_type":"code","source":"X = df[\"final_text\"]\nprint(X)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.119624Z","iopub.execute_input":"2023-12-15T15:00:17.119945Z","iopub.status.idle":"2023-12-15T15:00:17.130550Z","shell.execute_reply.started":"2023-12-15T15:00:17.119921Z","shell.execute_reply":"2023-12-15T15:00:17.129731Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"0     machinelearn dataset predict develop model cla...\n1     machinelearn learn appli perform transform pre...\n2     look tensorflow deep yolo ( implement learn co...\n3     social sentiment transform understand deep dat...\n4     contribut learn advanc openaigym develop model...\n5     machinelearn tensorflow applic gener ( adversa...\n6     portfolio creat , skill websit develop applic ...\n7     html5 develop websit user visualstudiocod expe...\n8     html5 applic nodej css3 socketio git architect...\n9     focu ui/uxdesign figma usabl websit user appli...\n10    scalabl system perform queri docker complex ap...\n11    scalabl contribut webpack develop css-in-j pop...\n12    tensorflow team pytorch deep learn natur appli...\n13    scalabl api full-stack develop architect mongo...\n14    machinelearn dataset predict data algorithm ju...\n15    html5 advanc develop websit applic web use jav...\n16    conduct dataset given perform dataanalysi libr...\n17    portfolio creat , skill websit develop applic ...\n18    sentiment tensorflow transform gener implement...\n19    game tensorflow algorithm implement learn comp...\n20    machinelearn explor dataset learn hands-on mod...\nName: final_text, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:17.131672Z","iopub.execute_input":"2023-12-15T15:00:17.131933Z","iopub.status.idle":"2023-12-15T15:00:29.377592Z","shell.execute_reply.started":"2023-12-15T15:00:17.131911Z","shell.execute_reply":"2023-12-15T15:00:29.376627Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"tokenizer.fit_on_texts(X)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.378873Z","iopub.execute_input":"2023-12-15T15:00:29.379540Z","iopub.status.idle":"2023-12-15T15:00:29.385065Z","shell.execute_reply.started":"2023-12-15T15:00:29.379503Z","shell.execute_reply":"2023-12-15T15:00:29.384089Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.386215Z","iopub.execute_input":"2023-12-15T15:00:29.386512Z","iopub.status.idle":"2023-12-15T15:00:29.422157Z","shell.execute_reply.started":"2023-12-15T15:00:29.386488Z","shell.execute_reply":"2023-12-15T15:00:29.421244Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'develop': 1,\n 'use': 2,\n 'learn': 3,\n 'python': 4,\n 'applic': 5,\n 'beginner': 6,\n 'intermediate': 7,\n 'advanced': 8,\n 'model': 9,\n 'implement': 10,\n 'javascript': 11,\n 'machinelearn': 12,\n 'scikit': 13,\n 'data': 14,\n 'tensorflow': 15,\n 'deeplearn': 16,\n 'led': 17,\n 'websit': 18,\n 'dataset': 19,\n 'basic': 20,\n 'analysi': 21,\n 'react': 22,\n 'e': 23,\n 'commerc': 24,\n 'predict': 25,\n 'perform': 26,\n 'transform': 27,\n 'panda': 28,\n 'machin': 29,\n 'deep': 30,\n 'system': 31,\n 'nlp': 32,\n 'built': 33,\n 'conduct': 34,\n 'contribut': 35,\n 'advanc': 36,\n 'css': 37,\n 'html5': 38,\n 'experi': 39,\n 'css3': 40,\n 'nodej': 41,\n 'expressj': 42,\n 'scalabl': 43,\n 'train': 44,\n 'simpl': 45,\n 'network': 46,\n 'imag': 47,\n 'appli': 48,\n 'clean': 49,\n 'task': 50,\n 'sale': 51,\n 'computervis': 52,\n 'opencv': 53,\n 'object': 54,\n 'techniqu': 55,\n 'recognit': 56,\n 'detect': 57,\n 'sentiment': 58,\n 'natur': 59,\n 'languag': 60,\n 'reinforc': 61,\n 'pytorch': 62,\n 'reinforcementlearn': 63,\n 'ai': 64,\n 'gener': 65,\n 'research': 66,\n 'portfolio': 67,\n 'creat': 68,\n 'skill': 69,\n 'project': 70,\n 'showcas': 71,\n 'person': 72,\n 'html': 73,\n 'to': 74,\n 'do': 75,\n 'user': 76,\n 'interact': 77,\n 'respons': 78,\n 'featur': 79,\n 'frontend': 80,\n 'architect': 81,\n 'full': 82,\n 'stack': 83,\n 'platform': 84,\n 'postman': 85,\n 'mongodb': 86,\n 'ui': 87,\n 'design': 88,\n 'improv': 89,\n 'architectur': 90,\n 'librari': 91,\n 'redux': 92,\n 'algorithm': 93,\n 'given': 94,\n 'dataanalysi': 95,\n 'classif': 96,\n 'neural': 97,\n 'iri': 98,\n 'analyt': 99,\n 'datapreprocess': 100,\n 'look': 101,\n 'yolo': 102,\n 'facial': 103,\n 'onli': 104,\n 'social': 105,\n 'understand': 106,\n 'media': 107,\n 'nltk': 108,\n 'chatbot': 109,\n 'openaigym': 110,\n 'aiethic': 111,\n 'creation': 112,\n 'ethic': 113,\n 'framework': 114,\n 'adversari': 115,\n 'healthcar': 116,\n 'driven': 117,\n 'paper': 118,\n 'gans': 119,\n 'researchpubl': 120,\n 'solut': 121,\n 'visualstudiocod': 122,\n 'enhanc': 123,\n 'socketio': 124,\n 'git': 125,\n 'real': 126,\n 'tim': 127,\n 'chat': 128,\n 'focu': 129,\n 'uxdesign': 130,\n 'figma': 131,\n 'usabl': 132,\n 'mobil': 133,\n 'adobexd': 134,\n 'redesign': 135,\n 'interfac': 136,\n 'queri': 137,\n 'docker': 138,\n 'complex': 139,\n 'databas': 140,\n 'restfulapi': 141,\n 'postgresql': 142,\n 'microservic': 143,\n 'optim': 144,\n 'webpack': 145,\n 'in': 146,\n 'j': 147,\n 'popular': 148,\n 'large': 149,\n 'scal': 150,\n 'vuej': 151,\n 'team': 152,\n 'purpos': 153,\n 'process': 154,\n 'api': 155,\n 'jupyternotebook': 156,\n 'extract': 157,\n 'insight': 158,\n 'statist': 159,\n 'web': 160,\n 'exploratori': 161,\n 'matplotlib': 162,\n 'bert': 163,\n 'lstm': 164,\n 'text': 165,\n 'corpu': 166,\n 'pre': 167,\n 'larg': 168,\n 'naturallanguageprocess': 169,\n 'kera': 170,\n 'game': 171,\n 'agent': 172,\n 'explor': 173,\n 'hands': 174,\n 'on': 175,\n 'analyz': 176,\n 'manipul': 177}"},"metadata":{}}]},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index)\nvocab_size","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.423247Z","iopub.execute_input":"2023-12-15T15:00:29.423510Z","iopub.status.idle":"2023-12-15T15:00:29.433518Z","shell.execute_reply.started":"2023-12-15T15:00:29.423487Z","shell.execute_reply":"2023-12-15T15:00:29.432717Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"177"},"metadata":{}}]},{"cell_type":"code","source":"input_sequences = tokenizer.texts_to_sequences(X)\ninput_sequences","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.434643Z","iopub.execute_input":"2023-12-15T15:00:29.434918Z","iopub.status.idle":"2023-12-15T15:00:29.454460Z","shell.execute_reply.started":"2023-12-15T15:00:29.434887Z","shell.execute_reply":"2023-12-15T15:00:29.453585Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"[[12, 19, 25, 1, 9, 96, 45, 46, 2, 97, 4, 13, 3, 47, 98, 10, 20, 6],\n [12, 3, 48, 26, 27, 25, 49, 2, 4, 13, 3, 28, 14, 99, 29, 50, 100, 51, 6],\n [101,\n  15,\n  30,\n  102,\n  10,\n  3,\n  52,\n  16,\n  103,\n  4,\n  104,\n  53,\n  54,\n  55,\n  31,\n  1,\n  56,\n  2,\n  57,\n  7],\n [105,\n  58,\n  27,\n  106,\n  30,\n  14,\n  3,\n  59,\n  16,\n  4,\n  60,\n  21,\n  32,\n  107,\n  33,\n  34,\n  2,\n  108,\n  109,\n  7],\n [35, 3, 36, 110, 1, 9, 61, 111, 5, 112, 113, 62, 4, 63, 17, 114, 64, 8],\n [12,\n  15,\n  5,\n  65,\n  115,\n  116,\n  64,\n  117,\n  46,\n  4,\n  118,\n  119,\n  35,\n  120,\n  66,\n  121,\n  1,\n  13,\n  3,\n  8],\n [67, 68, 69, 18, 1, 5, 70, 37, 2, 11, 71, 72, 73, 74, 75, 20, 6],\n [38, 1, 18, 76, 122, 39, 2, 11, 77, 22, 78, 79, 80, 40, 10, 123, 6],\n [38,\n  5,\n  41,\n  40,\n  124,\n  125,\n  81,\n  126,\n  127,\n  82,\n  83,\n  128,\n  84,\n  23,\n  24,\n  85,\n  33,\n  1,\n  2,\n  11,\n  42,\n  86,\n  7],\n [129,\n  87,\n  130,\n  131,\n  132,\n  18,\n  76,\n  5,\n  133,\n  39,\n  134,\n  88,\n  23,\n  24,\n  135,\n  17,\n  136,\n  89,\n  7],\n [43,\n  31,\n  26,\n  137,\n  138,\n  139,\n  5,\n  140,\n  42,\n  90,\n  88,\n  41,\n  141,\n  142,\n  143,\n  144,\n  89,\n  8],\n [43,\n  35,\n  145,\n  1,\n  37,\n  146,\n  147,\n  148,\n  91,\n  149,\n  150,\n  11,\n  5,\n  90,\n  22,\n  151,\n  80,\n  17,\n  92,\n  8],\n [15,\n  152,\n  62,\n  30,\n  3,\n  59,\n  48,\n  36,\n  16,\n  9,\n  4,\n  60,\n  153,\n  66,\n  32,\n  55,\n  1,\n  56,\n  154,\n  47,\n  17,\n  8],\n [43, 155, 82, 83, 1, 81, 86, 84, 2, 41, 42, 22, 23, 24, 85, 17, 8],\n [12,\n  19,\n  25,\n  14,\n  93,\n  156,\n  157,\n  3,\n  94,\n  9,\n  4,\n  158,\n  21,\n  51,\n  34,\n  1,\n  159,\n  2,\n  13,\n  3,\n  29,\n  7],\n [38, 36, 1, 18, 5, 160, 2, 11, 77, 22, 87, 79, 78, 23, 24, 40, 92, 33, 7],\n [34, 19, 94, 26, 95, 91, 49, 2, 4, 28, 161, 14, 21, 50, 162, 6],\n [67, 68, 69, 18, 1, 5, 70, 37, 2, 11, 71, 72, 73, 74, 75, 20, 6],\n [58,\n  15,\n  27,\n  65,\n  10,\n  16,\n  163,\n  9,\n  164,\n  165,\n  4,\n  166,\n  167,\n  44,\n  21,\n  168,\n  44,\n  32,\n  1,\n  169,\n  2,\n  170,\n  8],\n [171, 15, 93, 10, 3, 52, 16, 4, 44, 53, 172, 54, 31, 45, 1, 61, 2, 57, 63, 7],\n [12,\n  173,\n  19,\n  3,\n  174,\n  175,\n  9,\n  176,\n  95,\n  39,\n  2,\n  4,\n  28,\n  177,\n  14,\n  13,\n  3,\n  29,\n  10,\n  20,\n  6]]"},"metadata":{}}]},{"cell_type":"code","source":"max_len = max(len(i) for i in input_sequences)\nmax_len","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.455618Z","iopub.execute_input":"2023-12-15T15:00:29.455931Z","iopub.status.idle":"2023-12-15T15:00:29.465431Z","shell.execute_reply.started":"2023-12-15T15:00:29.455901Z","shell.execute_reply":"2023-12-15T15:00:29.464624Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\npadded_input_sequences = pad_sequences(sequences=input_sequences , maxlen=max_len , padding=\"pre\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.466314Z","iopub.execute_input":"2023-12-15T15:00:29.466622Z","iopub.status.idle":"2023-12-15T15:00:29.476751Z","shell.execute_reply.started":"2023-12-15T15:00:29.466588Z","shell.execute_reply":"2023-12-15T15:00:29.475888Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"padded_input_sequences","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.477788Z","iopub.execute_input":"2023-12-15T15:00:29.478043Z","iopub.status.idle":"2023-12-15T15:00:29.491112Z","shell.execute_reply.started":"2023-12-15T15:00:29.478021Z","shell.execute_reply":"2023-12-15T15:00:29.490223Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"array([[  0,   0,   0,   0,   0,  12,  19,  25,   1,   9,  96,  45,  46,\n          2,  97,   4,  13,   3,  47,  98,  10,  20,   6],\n       [  0,   0,   0,   0,  12,   3,  48,  26,  27,  25,  49,   2,   4,\n         13,   3,  28,  14,  99,  29,  50, 100,  51,   6],\n       [  0,   0,   0, 101,  15,  30, 102,  10,   3,  52,  16, 103,   4,\n        104,  53,  54,  55,  31,   1,  56,   2,  57,   7],\n       [  0,   0,   0, 105,  58,  27, 106,  30,  14,   3,  59,  16,   4,\n         60,  21,  32, 107,  33,  34,   2, 108, 109,   7],\n       [  0,   0,   0,   0,   0,  35,   3,  36, 110,   1,   9,  61, 111,\n          5, 112, 113,  62,   4,  63,  17, 114,  64,   8],\n       [  0,   0,   0,  12,  15,   5,  65, 115, 116,  64, 117,  46,   4,\n        118, 119,  35, 120,  66, 121,   1,  13,   3,   8],\n       [  0,   0,   0,   0,   0,   0,  67,  68,  69,  18,   1,   5,  70,\n         37,   2,  11,  71,  72,  73,  74,  75,  20,   6],\n       [  0,   0,   0,   0,   0,   0,  38,   1,  18,  76, 122,  39,   2,\n         11,  77,  22,  78,  79,  80,  40,  10, 123,   6],\n       [ 38,   5,  41,  40, 124, 125,  81, 126, 127,  82,  83, 128,  84,\n         23,  24,  85,  33,   1,   2,  11,  42,  86,   7],\n       [  0,   0,   0,   0, 129,  87, 130, 131, 132,  18,  76,   5, 133,\n         39, 134,  88,  23,  24, 135,  17, 136,  89,   7],\n       [  0,   0,   0,   0,   0,  43,  31,  26, 137, 138, 139,   5, 140,\n         42,  90,  88,  41, 141, 142, 143, 144,  89,   8],\n       [  0,   0,   0,  43,  35, 145,   1,  37, 146, 147, 148,  91, 149,\n        150,  11,   5,  90,  22, 151,  80,  17,  92,   8],\n       [  0,  15, 152,  62,  30,   3,  59,  48,  36,  16,   9,   4,  60,\n        153,  66,  32,  55,   1,  56, 154,  47,  17,   8],\n       [  0,   0,   0,   0,   0,   0,  43, 155,  82,  83,   1,  81,  86,\n         84,   2,  41,  42,  22,  23,  24,  85,  17,   8],\n       [  0,  12,  19,  25,  14,  93, 156, 157,   3,  94,   9,   4, 158,\n         21,  51,  34,   1, 159,   2,  13,   3,  29,   7],\n       [  0,   0,   0,   0,  38,  36,   1,  18,   5, 160,   2,  11,  77,\n         22,  87,  79,  78,  23,  24,  40,  92,  33,   7],\n       [  0,   0,   0,   0,   0,   0,   0,  34,  19,  94,  26,  95,  91,\n         49,   2,   4,  28, 161,  14,  21,  50, 162,   6],\n       [  0,   0,   0,   0,   0,   0,  67,  68,  69,  18,   1,   5,  70,\n         37,   2,  11,  71,  72,  73,  74,  75,  20,   6],\n       [ 58,  15,  27,  65,  10,  16, 163,   9, 164, 165,   4, 166, 167,\n         44,  21, 168,  44,  32,   1, 169,   2, 170,   8],\n       [  0,   0,   0, 171,  15,  93,  10,   3,  52,  16,   4,  44,  53,\n        172,  54,  31,  45,   1,  61,   2,  57,  63,   7],\n       [  0,   0,  12, 173,  19,   3, 174, 175,   9, 176,  95,  39,   2,\n          4,  28, 177,  14,  13,   3,  29,  10,  20,   6]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"X = padded_input_sequences[:,:-1]\ny = padded_input_sequences[:,-1]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.494424Z","iopub.execute_input":"2023-12-15T15:00:29.494703Z","iopub.status.idle":"2023-12-15T15:00:29.501020Z","shell.execute_reply.started":"2023-12-15T15:00:29.494680Z","shell.execute_reply":"2023-12-15T15:00:29.500208Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.502082Z","iopub.execute_input":"2023-12-15T15:00:29.502345Z","iopub.status.idle":"2023-12-15T15:00:29.515431Z","shell.execute_reply.started":"2023-12-15T15:00:29.502323Z","shell.execute_reply":"2023-12-15T15:00:29.514448Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([[  0,   0,   0,   0,   0,  12,  19,  25,   1,   9,  96,  45,  46,\n          2,  97,   4,  13,   3,  47,  98,  10,  20],\n       [  0,   0,   0,   0,  12,   3,  48,  26,  27,  25,  49,   2,   4,\n         13,   3,  28,  14,  99,  29,  50, 100,  51],\n       [  0,   0,   0, 101,  15,  30, 102,  10,   3,  52,  16, 103,   4,\n        104,  53,  54,  55,  31,   1,  56,   2,  57],\n       [  0,   0,   0, 105,  58,  27, 106,  30,  14,   3,  59,  16,   4,\n         60,  21,  32, 107,  33,  34,   2, 108, 109],\n       [  0,   0,   0,   0,   0,  35,   3,  36, 110,   1,   9,  61, 111,\n          5, 112, 113,  62,   4,  63,  17, 114,  64],\n       [  0,   0,   0,  12,  15,   5,  65, 115, 116,  64, 117,  46,   4,\n        118, 119,  35, 120,  66, 121,   1,  13,   3],\n       [  0,   0,   0,   0,   0,   0,  67,  68,  69,  18,   1,   5,  70,\n         37,   2,  11,  71,  72,  73,  74,  75,  20],\n       [  0,   0,   0,   0,   0,   0,  38,   1,  18,  76, 122,  39,   2,\n         11,  77,  22,  78,  79,  80,  40,  10, 123],\n       [ 38,   5,  41,  40, 124, 125,  81, 126, 127,  82,  83, 128,  84,\n         23,  24,  85,  33,   1,   2,  11,  42,  86],\n       [  0,   0,   0,   0, 129,  87, 130, 131, 132,  18,  76,   5, 133,\n         39, 134,  88,  23,  24, 135,  17, 136,  89],\n       [  0,   0,   0,   0,   0,  43,  31,  26, 137, 138, 139,   5, 140,\n         42,  90,  88,  41, 141, 142, 143, 144,  89],\n       [  0,   0,   0,  43,  35, 145,   1,  37, 146, 147, 148,  91, 149,\n        150,  11,   5,  90,  22, 151,  80,  17,  92],\n       [  0,  15, 152,  62,  30,   3,  59,  48,  36,  16,   9,   4,  60,\n        153,  66,  32,  55,   1,  56, 154,  47,  17],\n       [  0,   0,   0,   0,   0,   0,  43, 155,  82,  83,   1,  81,  86,\n         84,   2,  41,  42,  22,  23,  24,  85,  17],\n       [  0,  12,  19,  25,  14,  93, 156, 157,   3,  94,   9,   4, 158,\n         21,  51,  34,   1, 159,   2,  13,   3,  29],\n       [  0,   0,   0,   0,  38,  36,   1,  18,   5, 160,   2,  11,  77,\n         22,  87,  79,  78,  23,  24,  40,  92,  33],\n       [  0,   0,   0,   0,   0,   0,   0,  34,  19,  94,  26,  95,  91,\n         49,   2,   4,  28, 161,  14,  21,  50, 162],\n       [  0,   0,   0,   0,   0,   0,  67,  68,  69,  18,   1,   5,  70,\n         37,   2,  11,  71,  72,  73,  74,  75,  20],\n       [ 58,  15,  27,  65,  10,  16, 163,   9, 164, 165,   4, 166, 167,\n         44,  21, 168,  44,  32,   1, 169,   2, 170],\n       [  0,   0,   0, 171,  15,  93,  10,   3,  52,  16,   4,  44,  53,\n        172,  54,  31,  45,   1,  61,   2,  57,  63],\n       [  0,   0,  12, 173,  19,   3, 174, 175,   9, 176,  95,  39,   2,\n          4,  28, 177,  14,  13,   3,  29,  10,  20]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"len(X[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.516592Z","iopub.execute_input":"2023-12-15T15:00:29.516853Z","iopub.status.idle":"2023-12-15T15:00:29.525802Z","shell.execute_reply.started":"2023-12-15T15:00:29.516831Z","shell.execute_reply":"2023-12-15T15:00:29.524949Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.526756Z","iopub.execute_input":"2023-12-15T15:00:29.527000Z","iopub.status.idle":"2023-12-15T15:00:29.536368Z","shell.execute_reply.started":"2023-12-15T15:00:29.526978Z","shell.execute_reply":"2023-12-15T15:00:29.535631Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"array([6, 6, 7, 7, 8, 8, 6, 6, 7, 7, 8, 8, 8, 8, 7, 7, 6, 6, 8, 7, 6],\n      dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"len(X) , len(y)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.537277Z","iopub.execute_input":"2023-12-15T15:00:29.537500Z","iopub.status.idle":"2023-12-15T15:00:29.547525Z","shell.execute_reply.started":"2023-12-15T15:00:29.537481Z","shell.execute_reply":"2023-12-15T15:00:29.546714Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(21, 21)"},"metadata":{}}]},{"cell_type":"code","source":"from keras.utils import to_categorical\ny = to_categorical(y , num_classes=178)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.548379Z","iopub.execute_input":"2023-12-15T15:00:29.548645Z","iopub.status.idle":"2023-12-15T15:00:29.556320Z","shell.execute_reply.started":"2023-12-15T15:00:29.548620Z","shell.execute_reply":"2023-12-15T15:00:29.555625Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.557488Z","iopub.execute_input":"2023-12-15T15:00:29.557828Z","iopub.status.idle":"2023-12-15T15:00:29.568932Z","shell.execute_reply.started":"2023-12-15T15:00:29.557797Z","shell.execute_reply":"2023-12-15T15:00:29.568090Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"len(y[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.570080Z","iopub.execute_input":"2023-12-15T15:00:29.570336Z","iopub.status.idle":"2023-12-15T15:00:29.579372Z","shell.execute_reply.started":"2023-12-15T15:00:29.570313Z","shell.execute_reply":"2023-12-15T15:00:29.578301Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"178"},"metadata":{}}]},{"cell_type":"code","source":"num_classes = len(y[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.584250Z","iopub.execute_input":"2023-12-15T15:00:29.584518Z","iopub.status.idle":"2023-12-15T15:00:29.588976Z","shell.execute_reply.started":"2023-12-15T15:00:29.584495Z","shell.execute_reply":"2023-12-15T15:00:29.588150Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import Sequential\nfrom keras.layers import Embedding ,LSTM ,Dense ,Bidirectional","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.589849Z","iopub.execute_input":"2023-12-15T15:00:29.590125Z","iopub.status.idle":"2023-12-15T15:00:29.599356Z","shell.execute_reply.started":"2023-12-15T15:00:29.590102Z","shell.execute_reply":"2023-12-15T15:00:29.598603Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Embedding(input_dim=vocab_size+1 , output_dim=100 , input_length=22),\n    Bidirectional(LSTM(300 , return_sequences=True)),\n    Bidirectional(LSTM(150)),\n    Dense(units=num_classes , activation=\"softmax\")\n])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:29.600422Z","iopub.execute_input":"2023-12-15T15:00:29.601027Z","iopub.status.idle":"2023-12-15T15:00:34.949399Z","shell.execute_reply.started":"2023-12-15T15:00:29.600994Z","shell.execute_reply":"2023-12-15T15:00:34.948623Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"vocab_size+1 , num_classes , max_len","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:34.951260Z","iopub.execute_input":"2023-12-15T15:00:34.951539Z","iopub.status.idle":"2023-12-15T15:00:34.957366Z","shell.execute_reply.started":"2023-12-15T15:00:34.951514Z","shell.execute_reply":"2023-12-15T15:00:34.956438Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"(178, 178, 23)"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:34.958449Z","iopub.execute_input":"2023-12-15T15:00:34.958739Z","iopub.status.idle":"2023-12-15T15:00:34.984003Z","shell.execute_reply.started":"2023-12-15T15:00:34.958711Z","shell.execute_reply":"2023-12-15T15:00:34.983163Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T11:25:23.381157Z","iopub.execute_input":"2023-12-15T11:25:23.381448Z","iopub.status.idle":"2023-12-15T11:25:23.401160Z","shell.execute_reply.started":"2023-12-15T11:25:23.381425Z","shell.execute_reply":"2023-12-15T11:25:23.400145Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 22, 100)           17800     \n                                                                 \n lstm (LSTM)                 (None, 150)               150600    \n                                                                 \n dense (Dense)               (None, 178)               26878     \n                                                                 \n=================================================================\nTotal params: 195278 (762.80 KB)\nTrainable params: 195278 (762.80 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit( X , y , epochs=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:40.255114Z","iopub.execute_input":"2023-12-15T15:00:40.255472Z","iopub.status.idle":"2023-12-15T15:00:56.412593Z","shell.execute_reply.started":"2023-12-15T15:00:40.255436Z","shell.execute_reply":"2023-12-15T15:00:56.411628Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Epoch 1/100\n1/1 [==============================] - 12s 12s/step - loss: 5.1838 - accuracy: 0.0000e+00\nEpoch 2/100\n1/1 [==============================] - 0s 19ms/step - loss: 5.1275 - accuracy: 0.6190\nEpoch 3/100\n1/1 [==============================] - 0s 19ms/step - loss: 5.0484 - accuracy: 0.5238\nEpoch 4/100\n1/1 [==============================] - 0s 19ms/step - loss: 4.8975 - accuracy: 0.4762\nEpoch 5/100\n1/1 [==============================] - 0s 19ms/step - loss: 4.5643 - accuracy: 0.3333\nEpoch 6/100\n1/1 [==============================] - 0s 19ms/step - loss: 3.7861 - accuracy: 0.3333\nEpoch 7/100\n1/1 [==============================] - 0s 20ms/step - loss: 2.4091 - accuracy: 0.3333\nEpoch 8/100\n1/1 [==============================] - 0s 19ms/step - loss: 1.4856 - accuracy: 0.3333\nEpoch 9/100\n1/1 [==============================] - 0s 19ms/step - loss: 1.2037 - accuracy: 0.3333\nEpoch 10/100\n1/1 [==============================] - 0s 19ms/step - loss: 1.1299 - accuracy: 0.3333\nEpoch 11/100\n1/1 [==============================] - 0s 19ms/step - loss: 1.1378 - accuracy: 0.3333\nEpoch 12/100\n1/1 [==============================] - 0s 18ms/step - loss: 1.1077 - accuracy: 0.3333\nEpoch 13/100\n1/1 [==============================] - 0s 19ms/step - loss: 1.1105 - accuracy: 0.3333\nEpoch 14/100\n1/1 [==============================] - 0s 17ms/step - loss: 1.1162 - accuracy: 0.3333\nEpoch 15/100\n1/1 [==============================] - 0s 17ms/step - loss: 1.0962 - accuracy: 0.3333\nEpoch 16/100\n1/1 [==============================] - 0s 17ms/step - loss: 1.1082 - accuracy: 0.3333\nEpoch 17/100\n1/1 [==============================] - 0s 16ms/step - loss: 1.0963 - accuracy: 0.3333\nEpoch 18/100\n1/1 [==============================] - 0s 16ms/step - loss: 1.0942 - accuracy: 0.3333\nEpoch 19/100\n1/1 [==============================] - 0s 16ms/step - loss: 1.0910 - accuracy: 0.5238\nEpoch 20/100\n1/1 [==============================] - 0s 17ms/step - loss: 1.0876 - accuracy: 0.4286\nEpoch 21/100\n1/1 [==============================] - 0s 17ms/step - loss: 1.0861 - accuracy: 0.5714\nEpoch 22/100\n1/1 [==============================] - 0s 17ms/step - loss: 1.0834 - accuracy: 0.3333\nEpoch 23/100\n1/1 [==============================] - 0s 16ms/step - loss: 1.0790 - accuracy: 0.4286\nEpoch 24/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0780 - accuracy: 0.4762\nEpoch 25/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0749 - accuracy: 0.5238\nEpoch 26/100\n1/1 [==============================] - 0s 16ms/step - loss: 1.0696 - accuracy: 0.4286\nEpoch 27/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0700 - accuracy: 0.3810\nEpoch 28/100\n1/1 [==============================] - 0s 16ms/step - loss: 1.0702 - accuracy: 0.3333\nEpoch 29/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0618 - accuracy: 0.4762\nEpoch 30/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0547 - accuracy: 0.4286\nEpoch 31/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0572 - accuracy: 0.3333\nEpoch 32/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0470 - accuracy: 0.4286\nEpoch 33/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0366 - accuracy: 0.5714\nEpoch 34/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0285 - accuracy: 0.6190\nEpoch 35/100\n1/1 [==============================] - 0s 15ms/step - loss: 1.0264 - accuracy: 0.4762\nEpoch 36/100\n1/1 [==============================] - 0s 14ms/step - loss: 1.0367 - accuracy: 0.3333\nEpoch 37/100\n1/1 [==============================] - 0s 14ms/step - loss: 1.0050 - accuracy: 0.6667\nEpoch 38/100\n1/1 [==============================] - 0s 14ms/step - loss: 1.0029 - accuracy: 0.6190\nEpoch 39/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.9870 - accuracy: 0.4762\nEpoch 40/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.9839 - accuracy: 0.4762\nEpoch 41/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.9460 - accuracy: 0.7619\nEpoch 42/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.9443 - accuracy: 0.5714\nEpoch 43/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.9137 - accuracy: 0.4286\nEpoch 44/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.8532 - accuracy: 0.5714\nEpoch 45/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.8535 - accuracy: 0.9048\nEpoch 46/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.8106 - accuracy: 0.7143\nEpoch 47/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.7701 - accuracy: 0.8095\nEpoch 48/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.8095\nEpoch 49/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.6235 - accuracy: 0.7619\nEpoch 50/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.5411 - accuracy: 0.9048\nEpoch 51/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.5240 - accuracy: 0.9048\nEpoch 52/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4695 - accuracy: 1.0000\nEpoch 53/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.4335 - accuracy: 0.9524\nEpoch 54/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.4217 - accuracy: 0.9524\nEpoch 55/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.3910 - accuracy: 1.0000\nEpoch 56/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.3731 - accuracy: 0.9524\nEpoch 57/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4611 - accuracy: 0.9048\nEpoch 58/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4347 - accuracy: 0.9524\nEpoch 59/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.9524\nEpoch 60/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.9524\nEpoch 61/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4137 - accuracy: 0.9048\nEpoch 62/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4197 - accuracy: 0.8571\nEpoch 63/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4215 - accuracy: 0.8095\nEpoch 64/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4228 - accuracy: 1.0000\nEpoch 65/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4333 - accuracy: 0.8095\nEpoch 66/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4230 - accuracy: 0.8571\nEpoch 67/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4418 - accuracy: 0.7143\nEpoch 68/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4334 - accuracy: 0.7143\nEpoch 69/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.9048\nEpoch 70/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.4069 - accuracy: 0.6667\nEpoch 71/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.3895 - accuracy: 0.8095\nEpoch 72/100\n1/1 [==============================] - 0s 14ms/step - loss: 0.3656 - accuracy: 0.9048\nEpoch 73/100\n1/1 [==============================] - 0s 19ms/step - loss: 0.3606 - accuracy: 0.7619\nEpoch 74/100\n1/1 [==============================] - 0s 24ms/step - loss: 0.3461 - accuracy: 0.9524\nEpoch 75/100\n1/1 [==============================] - 0s 20ms/step - loss: 0.3346 - accuracy: 1.0000\nEpoch 76/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.3234 - accuracy: 0.9524\nEpoch 77/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.3139 - accuracy: 0.9048\nEpoch 78/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.3024 - accuracy: 0.9524\nEpoch 79/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.2884 - accuracy: 0.9524\nEpoch 80/100\n1/1 [==============================] - 0s 23ms/step - loss: 0.2721 - accuracy: 0.9524\nEpoch 81/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.2607 - accuracy: 1.0000\nEpoch 82/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.2410 - accuracy: 0.9524\nEpoch 83/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.2291 - accuracy: 1.0000\nEpoch 84/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.2058 - accuracy: 1.0000\nEpoch 85/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.2829 - accuracy: 0.9524\nEpoch 86/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.1808 - accuracy: 0.9524\nEpoch 87/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.1699 - accuracy: 1.0000\nEpoch 88/100\n1/1 [==============================] - 0s 24ms/step - loss: 0.1489 - accuracy: 1.0000\nEpoch 89/100\n1/1 [==============================] - 0s 19ms/step - loss: 0.1324 - accuracy: 1.0000\nEpoch 90/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.1135 - accuracy: 1.0000\nEpoch 91/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.0975 - accuracy: 1.0000\nEpoch 92/100\n1/1 [==============================] - 0s 18ms/step - loss: 0.0893 - accuracy: 1.0000\nEpoch 93/100\n1/1 [==============================] - 0s 20ms/step - loss: 0.0710 - accuracy: 1.0000\nEpoch 94/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.0601 - accuracy: 1.0000\nEpoch 95/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.0532 - accuracy: 1.0000\nEpoch 96/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.0405 - accuracy: 1.0000\nEpoch 97/100\n1/1 [==============================] - 0s 17ms/step - loss: 0.1098 - accuracy: 0.9524\nEpoch 98/100\n1/1 [==============================] - 0s 19ms/step - loss: 0.0324 - accuracy: 1.0000\nEpoch 99/100\n1/1 [==============================] - 0s 16ms/step - loss: 0.0284 - accuracy: 1.0000\nEpoch 100/100\n1/1 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 1.0000\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7fcd1664fc70>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:01:56.740875Z","iopub.execute_input":"2023-12-15T15:01:56.741258Z","iopub.status.idle":"2023-12-15T15:01:56.746031Z","shell.execute_reply.started":"2023-12-15T15:01:56.741226Z","shell.execute_reply":"2023-12-15T15:01:56.744944Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"test = [\n{\n  \"text\": \"AI enthusiast with hands-on experience in computer vision and reinforcement learning...\",\n  \"skills\": [\"Python\", \"Computer Vision\", \"Reinforcement Learning\"],\n  \"projects\": [\n    {\"name\": \"Object Detection using OpenCV\", \"description\": \"Implemented an object detection system using OpenCV and Python.\", \"github_link\": \"\"},\n    {\"name\": \"Reinforcement Learning Game\", \"description\": \"Developed a simple game with reinforcement learning algorithms for training agents.\", \"github_link\": \"\"}\n  ],\n  \"tools\": [\"TensorFlow\", \"Keras\"],\n  \"frameworks\": [\"Deep Learning\", \"Reinforcement Learning\"],\n  \"experience_level\": \"Intermediate\"\n},\n{\n    \"text\": \"Aspiring AI enthusiast with a foundational understanding of machine learning and neural networks...\",\n    \"skills\": [\"Python\", \"Machine Learning\"],\n    \"projects\": [\n      {\"name\": \"Basic Image Classification\", \"description\": \"Implemented a basic image classification model using a simple neural network.\", \"github_link\": \"\"},\n      {\"name\": \"Predictive Model for Iris Dataset\", \"description\": \"Developed a predictive model for the Iris dataset using Scikit-learn.\", \"github_link\": \"\"}\n    ],\n    \"tools\": [\"Scikit-learn\"],\n    \"frameworks\": [],\n    \"experience_level\": \"Beginner\"\n  },\n    {\n        \"text\": \"Passionate data scientist specializing in natural language processing and text mining...\",\n        \"skills\": [\"Python\", \"NLP\", \"Text Mining\"],\n        \"projects\": [\n            {\"name\": \"Sentiment Analysis with NLTK\", \"description\": \"Conducted sentiment analysis using NLTK library on customer reviews.\", \"github_link\": \"\"},\n            {\"name\": \"Named Entity Recognition\", \"description\": \"Built a model for identifying named entities in text documents.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"NLTK\", \"Spacy\"],\n        \"frameworks\": [\"Machine Learning\", \"Natural Language Processing\"],\n        \"experience_level\": \"Advanced\"\n    },\n    {\n        \"text\": \"Data engineering enthusiast with expertise in building scalable data pipelines and ETL processes...\",\n        \"skills\": [\"Python\", \"ETL\", \"Data Pipelines\"],\n        \"projects\": [\n            {\"name\": \"ETL Pipeline for Customer Data\", \"description\": \"Designed and implemented an ETL pipeline for processing and analyzing customer data.\", \"github_link\": \"\"},\n            {\"name\": \"Real-time Data Streaming\", \"description\": \"Implemented a real-time data streaming application for monitoring system metrics.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"Apache Spark\", \"Airflow\"],\n        \"frameworks\": [\"Big Data\", \"Data Engineering\"],\n        \"experience_level\": \"Advanced\"\n    },\n    {\n        \"text\": \"Experienced machine learning practitioner with a focus on computer vision and image processing...\",\n        \"skills\": [\"Python\", \"Machine Learning\", \"Computer Vision\"],\n        \"projects\": [\n            {\"name\": \"Image Segmentation using OpenCV\", \"description\": \"Implemented image segmentation techniques using OpenCV for identifying objects.\", \"github_link\": \"\"},\n            {\"name\": \"Facial Recognition System\", \"description\": \"Developed a facial recognition system using deep learning for security applications.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"OpenCV\", \"TensorFlow\"],\n        \"frameworks\": [\"Deep Learning\", \"Computer Vision\"],\n        \"experience_level\": \"Intermediate\"\n    },\n    {\n        \"text\": \"Data analyst with proficiency in statistical analysis and visualization...\",\n        \"skills\": [\"Python\", \"Data Analysis\", \"Statistics\"],\n        \"projects\": [\n            {\"name\": \"Exploratory Data Analysis (EDA) on Sales Data\", \"description\": \"Conducted EDA to extract insights and patterns from sales data.\", \"github_link\": \"\"},\n            {\"name\": \"Statistical Modeling for Business Forecasting\", \"description\": \"Built statistical models to predict business trends and make forecasting decisions.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"Pandas\", \"Matplotlib\", \"StatsModels\"],\n        \"frameworks\": [],\n        \"experience_level\": \"Intermediate\"\n    },\n    {\n        \"text\": \"AI developer with a passion for developing chatbots and conversational agents...\",\n        \"skills\": [\"Python\", \"Natural Language Processing\", \"Chatbot Development\"],\n        \"projects\": [\n            {\"name\": \"Chatbot for Customer Support\", \"description\": \"Built a chatbot to handle customer inquiries and provide support.\", \"github_link\": \"\"},\n            {\"name\": \"Conversational AI for Virtual Assistants\", \"description\": \"Developed a conversational AI model for virtual assistant applications.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"NLTK\", \"Rasa\"],\n        \"frameworks\": [\"Natural Language Processing\", \"Chatbot Frameworks\"],\n        \"experience_level\": \"Intermediate\"\n    },\n    {\n        \"text\": \"Enthusiastic learner with a keen interest in web development and front-end technologies...\",\n        \"skills\": [\"HTML\", \"CSS\", \"JavaScript\"],\n        \"projects\": [\n            {\"name\": \"Personal Portfolio Website\", \"description\": \"Built a simple portfolio website showcasing personal projects and skills.\", \"github_link\": \"\"},\n            {\"name\": \"Interactive Web Page with JavaScript\", \"description\": \"Created an interactive web page using JavaScript for user engagement.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"VS Code\"],\n        \"frameworks\": [],\n        \"experience_level\": \"Beginner\"\n    },\n    {\n        \"text\": \"Aspiring data science enthusiast exploring the basics of data analysis and visualization...\",\n        \"skills\": [\"Python\", \"Data Analysis\", \"Matplotlib\"],\n        \"projects\": [\n            {\"name\": \"Basic Data Visualization with Matplotlib\", \"description\": \"Performed basic data visualization on sample datasets using Matplotlib.\", \"github_link\": \"\"},\n            {\"name\": \"Introduction to Pandas\", \"description\": \"Learned and implemented basic data analysis tasks using Pandas library.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"Jupyter Notebook\"],\n        \"frameworks\": [],\n        \"experience_level\": \"Beginner\"\n    },\n    {\n        \"text\": \"Tech enthusiast with a focus on cybersecurity basics and ethical hacking principles...\",\n        \"skills\": [\"Cybersecurity Fundamentals\", \"Ethical Hacking\", \"Networking Basics\"],\n        \"projects\": [\n            {\"name\": \"Introduction to Ethical Hacking\", \"description\": \"Explored basic ethical hacking techniques in a controlled environment.\", \"github_link\": \"\"},\n            {\"name\": \"Network Security Basics\", \"description\": \"Learned and implemented fundamental concepts of network security.\", \"github_link\": \"\"}\n        ],\n        \"tools\": [\"Wireshark\", \"Kali Linux\"],\n        \"frameworks\": [],\n        \"experience_level\": \"Beginner\"\n    }\n]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:06:51.637901Z","iopub.execute_input":"2023-12-15T15:06:51.638296Z","iopub.status.idle":"2023-12-15T15:06:51.660108Z","shell.execute_reply.started":"2023-12-15T15:06:51.638267Z","shell.execute_reply":"2023-12-15T15:06:51.659362Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame from test data\ndf_test = pd.DataFrame(test)\n\n# Extracting project descriptions from the 'projects' list of dictionaries\nx = []\nfor project_list in df_test[\"projects\"]:\n    y = []\n    for project in project_list:\n        y.append(project[\"description\"])\n    x.append(y)\n\ndf_test[\"projects\"] = x\n\n# Remove spaces from skills, tools, and frameworks\ndf_test[\"skills\"] = df_test[\"skills\"].apply(lambda x: [i.replace(\" \", \"\") for i in x])\ndf_test[\"tools\"] = df_test[\"tools\"].apply(lambda x: [i.replace(\" \", \"\") for i in x])\ndf_test[\"frameworks\"] = df_test[\"frameworks\"].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n\n# Combine skills, projects, tools, and frameworks into 'text' column\ndf_test[\"text\"] = df_test[\"skills\"] + df_test[\"projects\"] + df_test[\"tools\"] + df_test[\"frameworks\"]\n\n# Remove periods from 'text' column\ndf_test['text'] = df_test['text'].apply(lambda x: remove_periods_in_list(x))\n\n# Convert 'text' to lowercase\ndf_test[\"text\"] = [[i.lower() for i in listt] for listt in df_test[\"text\"]]\n\n# Remove duplicates within each list in the 'text' column\ndf_test['text'] = df_test['text'].apply(lambda x: remove_duplicates(x))\n\n# Join the lists in 'text' column into a string\ndf_test[\"text\"] = [\" \".join(i) for i in df_test[\"text\"]]\n\n# Apply stemming to the 'text' column\ndf_test[\"text\"] = df_test[\"text\"].apply(stem)\n\n# Tokenize and remove stopwords from 'text' column\ndf_test['filtered_text'] = df_test['text'].apply(lambda sentence: ' '.join([word for word in word_tokenize(sentence) if word.lower() not in set(stopwords.words('english'))]))\n\n# Convert 'filtered_text' to a list of words\ndf_test[\"filtered_text\"] = df_test[\"filtered_text\"].apply(lambda x: x.split())\n\n# Remove duplicates within each list in the 'filtered_text' column\ndf_test['filtered_text'] = df_test['filtered_text'].apply(lambda x: remove_duplicates(x))\n\ntext_test_str = df_test['filtered_text'].apply(lambda x: ' '.join(x))\n\n# Display the result\ntext_test_str","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:06:52.850113Z","iopub.execute_input":"2023-12-15T15:06:52.851031Z","iopub.status.idle":"2023-12-15T15:06:52.923138Z","shell.execute_reply.started":"2023-12-15T15:06:52.850997Z","shell.execute_reply":"2023-12-15T15:06:52.922272Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"0    game tensorflow algorithm implement learn comp...\n1    machinelearn dataset predict develop model cla...\n2    machinelearn sentiment custom identifi model t...\n3    datapipelin custom applic data implement pipel...\n4    machinelearn tensorflow applic deep implement ...\n5    predict panda data matplotlib eda extract fore...\n6    convers rasa custom applic assist support hand...\n7    web person creat skill websit css portfolio in...\n8    visual dataset learn sampl perform dataanalysi...\n9    explor ethicalhack learn techniqu fundament ne...\nName: filtered_text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"text = text_test_str[9]\n#lower()\ntext = text.lower()\n#tokenize\ntokenized_text = tokenizer.texts_to_sequences([text])[0]\n#padding\npadded_tokenized_text = pad_sequences(sequences=[tokenized_text] ,maxlen=22 ,padding=\"pre\")\n#predict\npos = np.argmax(model.predict(padded_tokenized_text))\n\nfor word,index in tokenizer.word_index.items():\n    if index == pos:\n        print(word)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:05.906633Z","iopub.execute_input":"2023-12-15T15:07:05.907029Z","iopub.status.idle":"2023-12-15T15:07:05.974808Z","shell.execute_reply.started":"2023-12-15T15:07:05.906998Z","shell.execute_reply":"2023-12-15T15:07:05.973836Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 21ms/step\nbeginner\n","output_type":"stream"}]},{"cell_type":"code","source":" ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}